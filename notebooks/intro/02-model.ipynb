{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch; torch.set_grad_enabled(False)\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "model_name = \"roneneldan/TinyStories-1M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jett/Documents/jett/tinyevals/.venv/lib/python3.10/site-packages/huggingface_hub/repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
      "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "094ba3aa7aa346fb9a233d690b41c1a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import load_orig_ds_txt, tokenize\n",
    "ds_txt = load_orig_ds_txt(\"validation[:100]\")\n",
    "ds_tok = [tokenize(tokenizer, txt) for txt in ds_txt]\n",
    "sample_tok = ds_tok[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logits(model, sample_tok):\n",
    "    sample_tok = sample_tok.unsqueeze(0)\n",
    "    return model(sample_tok).logits[0]\n",
    "\n",
    "def get_correct_probs(logits, sample_tok):\n",
    "    # pos, d_vocab\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    # drop the value for the last position, as we don't know\n",
    "    # what is the correct next token there\n",
    "    probs = probs[:-1]\n",
    "    # out of d_vocab values, take the one that corresponds to the correct next token\n",
    "    return probs[range(len(probs)), sample_tok[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.1341e-07, 3.8516e-03, 3.8292e-03, 1.2702e-03, 2.6244e-02, 5.7214e-03,\n",
       "        6.9342e-03, 2.1320e-01, 7.5029e-03, 7.4739e-01, 9.8252e-01, 5.3241e-02,\n",
       "        9.0845e-01, 1.9862e-04, 1.2865e-01, 1.9049e-02, 3.7672e-01, 8.3394e-01,\n",
       "        5.8995e-01, 7.8704e-03, 9.3007e-02, 1.0252e-03, 1.6984e-01, 6.3082e-02,\n",
       "        7.9264e-02, 9.3585e-01, 3.5446e-03, 9.8924e-01, 9.9815e-01, 1.6970e-01,\n",
       "        9.9656e-01, 8.5609e-01, 6.6405e-01, 1.9771e-01, 1.8745e-01, 3.4450e-06,\n",
       "        6.2227e-01, 1.1502e-01, 8.9421e-01, 7.8436e-01, 4.2450e-01, 9.5226e-01,\n",
       "        8.0645e-03, 3.1316e-01, 2.5546e-01, 2.1434e-01, 3.2364e-01, 9.7244e-01,\n",
       "        3.6453e-01, 2.6221e-01, 3.2694e-01, 3.1549e-03, 5.4743e-04, 7.2140e-01,\n",
       "        7.3100e-01, 7.1458e-03, 6.7133e-01, 1.7639e-02, 2.8133e-03, 2.0983e-01,\n",
       "        4.1505e-04, 5.5878e-01, 3.2920e-01, 2.2728e-01, 2.7677e-02, 1.8162e-01,\n",
       "        8.5580e-01, 8.0620e-01, 2.9107e-02, 5.5225e-02, 4.0758e-01, 8.9057e-01,\n",
       "        1.8427e-01, 2.4617e-01, 1.4175e-01, 2.9302e-01, 9.7246e-01, 1.8332e-01,\n",
       "        3.9763e-02, 4.5771e-02, 9.9756e-01, 9.6371e-01])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = get_logits(model, sample_tok)\n",
    "correct_probs = get_correct_probs(logits, sample_tok)\n",
    "correct_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        |Spot| 0.00%\n",
      "           |.| 0.39%\n",
      "       | Spot| 0.38%\n",
      "        | saw| 0.13%\n",
      "        | the| 2.62%\n",
      "      | shiny| 0.57%\n",
      "        | car| 0.69%\n",
      "        | and| 21.32%\n",
      "       | said| 0.75%\n",
      "           |,| 74.74%\n",
      "          | \"| 98.25%\n",
      "         |Wow| 5.32%\n",
      "           |,| 90.84%\n",
      "      | Kitty| 0.02%\n",
      "           |,| 12.87%\n",
      "       | your| 1.90%\n",
      "        | car| 37.67%\n",
      "         | is| 83.39%\n",
      "         | so| 59.00%\n",
      "     | bright| 0.79%\n",
      "        | and| 9.30%\n",
      "      | clean| 0.10%\n",
      "          |!\"| 16.98%\n",
      "      | Kitty| 6.31%\n",
      "     | smiled| 7.93%\n",
      "        | and| 93.59%\n",
      "    | replied| 0.35%\n",
      "           |,| 98.92%\n",
      "          | \"| 99.81%\n",
      "       |Thank| 16.97%\n",
      "        | you| 99.66%\n",
      "           |,| 85.61%\n",
      "       | Spot| 66.40%\n",
      "           |.| 19.77%\n",
      "          | I| 18.75%\n",
      "     | polish| 0.00%\n",
      "         | it| 62.23%\n",
      "      | every| 11.50%\n",
      "        | day| 89.42%\n",
      "          |.\"| 78.44%\n",
      "          |\\n| 42.45%\n",
      "          |\\n| 95.23%\n",
      "       |After| 0.81%\n",
      "    | playing| 31.32%\n",
      "       | with| 25.55%\n",
      "        | the| 21.43%\n",
      "        | car| 32.36%\n",
      "           |,| 97.24%\n",
      "      | Kitty| 36.45%\n",
      "        | and| 26.22%\n",
      "       | Spot| 32.69%\n",
      "       | felt| 0.32%\n",
      "    | thirsty| 0.05%\n",
      "           |.| 72.14%\n",
      "       | They| 73.10%\n",
      "      | found| 0.71%\n",
      "          | a| 67.13%\n",
      "      | small| 1.76%\n",
      "       | pond| 0.28%\n",
      "       | with| 20.98%\n",
      "      | clear| 0.04%\n",
      "      | water| 55.88%\n",
      "           |.| 32.92%\n",
      "       | They| 22.73%\n",
      "      | drank| 2.77%\n",
      "        | the| 18.16%\n",
      "      | water| 85.58%\n",
      "        | and| 80.62%\n",
      "       | felt| 2.91%\n",
      "       | very| 5.52%\n",
      "      | happy| 40.76%\n",
      "           |.| 89.06%\n",
      "       | They| 18.43%\n",
      "     | played| 24.62%\n",
      "   | together| 14.18%\n",
      "        | all| 29.30%\n",
      "        | day| 97.25%\n",
      "        | and| 18.33%\n",
      "     | became| 3.98%\n",
      "       | best| 4.58%\n",
      "    | friends| 99.76%\n",
      "           |.| 96.37%\n"
     ]
    }
   ],
   "source": [
    "for i in range(correct_probs.shape[0]):\n",
    "    tok_str = tokenizer.decode(sample_tok[i+1])\n",
    "    tok_str = tok_str.replace(\"\\n\", r\"\\n\")\n",
    "    tok_str_pipes = f\"|{tok_str}|\"\n",
    "    prob = correct_probs[i].item()\n",
    "    print(f\"{tok_str_pipes:>14} {prob:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
